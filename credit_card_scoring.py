# -*- coding: utf-8 -*-
"""Credit_card_Scoring.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13a08nr-cxEjSDKR9NKB32zdrXxyH2r5X
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv("bank.csv")
df.head()

df = pd.read_csv("bank.csv", sep=";", engine="python")
df.head()

df.dtypes

categorical_cols = df.select_dtypes(include=['object']).columns
print("Categorical Columns:", categorical_cols)

df.fillna(df.select_dtypes(include=['number']).median(), inplace=True)

for col in categorical_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)

df = pd.get_dummies(df, drop_first=True)

print(df.dtypes)

print(df.columns)

from sklearn.model_selection import train_test_split

# Define feature set (X) and target (y)
X = df.drop(columns=['y_yes'])  # Drop target column
y = df['y_yes']  # Target variable

# Split into 80% train, 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Train size:", X_train.shape)
print("Test size:", X_test.shape)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.ensemble import RandomForestClassifier

# Train the model first
model = RandomForestClassifier(n_estimators=50, max_depth=7, class_weight="balanced", random_state=42)
model.fit(X_train_scaled, y_train)  # ✅ Train the model first

import numpy as np

feature_importances = model.feature_importances_
important_features = np.argsort(feature_importances)[-20:]  # Keep Top 20 Features

X_train_selected = X_train_scaled[:, important_features]
X_test_selected = X_test_scaled[:, important_features]

model.fit(X_train_selected, y_train)  # ✅ Train Again with Selected Features

from sklearn.metrics import accuracy_score, classification_report

y_train_pred = model.predict(X_train_selected)
y_test_pred = model.predict(X_test_selected)

print("Train Accuracy:", accuracy_score(y_train, y_train_pred))
print("Test Accuracy:", accuracy_score(y_test, y_test_pred))
print("\nClassification Report:\n", classification_report(y_test, y_test_pred))

model = RandomForestClassifier(n_estimators=50, max_depth=7, class_weight={False: 1, True: 3}, random_state=42)
model.fit(X_train_selected, y_train)

model = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight="balanced", random_state=42)
model.fit(X_train_selected, y_train)

from imblearn.over_sampling import SMOTE

smote = SMOTE(sampling_strategy='auto', random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected, y_train)

model.fit(X_train_resampled, y_train_resampled)

model.fit(X_train_resampled, y_train_resampled)

y_train_pred = model.predict(X_train_selected)
y_test_pred = model.predict(X_test_selected)

print("Train Accuracy:", accuracy_score(y_train, y_train_pred))
print("Test Accuracy:", accuracy_score(y_test, y_test_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_test_pred))

import numpy as np
import matplotlib.pyplot as plt

feature_importances = model.feature_importances_
important_features = np.argsort(feature_importances)[-20:]  # Top 20 features

plt.figure(figsize=(10, 6))
plt.barh(np.array(X_train_selected.columns)[important_features], feature_importances[important_features])
plt.xlabel("Feature Importance")
plt.ylabel("Features")
plt.title("Top 20 Important Features")
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Extract feature names (fixing the AttributeError)
feature_names = X_train.columns  # Use the original column names before selection

feature_importances = model.feature_importances_
important_features = np.argsort(feature_importances)[-20:]  # Top 20 features

plt.figure(figsize=(10, 6))
plt.barh(np.array(feature_names)[important_features], feature_importances[important_features])
plt.xlabel("Feature Importance")
plt.ylabel("Features")
plt.title("Top 20 Important Features")
plt.show()

model.set_params(n_estimators=200, max_depth=10,
                 min_samples_split=5, min_samples_leaf=3,
                 class_weight="balanced")
model.fit(X_train_selected, y_train)

from sklearn.metrics import accuracy_score, classification_report

y_train_pred = model.predict(X_train_selected)
y_test_pred = model.predict(X_test_selected)

print("Train Accuracy:", accuracy_score(y_train, y_train_pred))
print("Test Accuracy:", accuracy_score(y_test, y_test_pred))
print("\nClassification Report:\n", classification_report(y_test, y_test_pred))

import numpy as np
import matplotlib.pyplot as plt

# Ensure X_train_selected has column names
feature_names = X_train.columns  # Original feature names before selection
feature_importances = model.feature_importances_

# Sort feature importance and get indices of top 20
important_features = np.argsort(feature_importances)[-20:]

plt.figure(figsize=(10, 6))
plt.barh(np.array(feature_names)[important_features], feature_importances[important_features])
plt.xlabel("Feature Importance")
plt.ylabel("Features")
plt.title("Top 20 Important Features")
plt.show()

import pandas as pd

# Define sample test cases
sample_data = pd.DataFrame([
    {"previous": 2, "age": 45, "balance": 5000, "campaign": 3, "pdays": 15, "duration": 200, "day": 5,
     "job_self-employed": 0, "job_blue-collar": 0, "job_entrepreneur": 1, "job_services": 0,
     "job_management": 0, "job_housemaid": 0, "job_student": 0, "job_technician": 0, "job_unknown": 0,
     "job_retired": 0, "marital_married": 1, "job_unemployed": 0, "marital_single": 0},

    {"previous": 0, "age": 30, "balance": 2000, "campaign": 1, "pdays": -1, "duration": 100, "day": 12,
     "job_self-employed": 0, "job_blue-collar": 1, "job_entrepreneur": 0, "job_services": 0,
     "job_management": 0, "job_housemaid": 0, "job_student": 0, "job_technician": 0, "job_unknown": 0,
     "job_retired": 0, "marital_married": 0, "job_unemployed": 0, "marital_single": 1},

    {"previous": 5, "age": 60, "balance": 15000, "campaign": 2, "pdays": 20, "duration": 400, "day": 18,
     "job_self-employed": 0, "job_blue-collar": 0, "job_entrepreneur": 0, "job_services": 0,
     "job_management": 1, "job_housemaid": 0, "job_student": 0, "job_technician": 0, "job_unknown": 0,
     "job_retired": 0, "marital_married": 1, "job_unemployed": 0, "marital_single": 0}
])

# Predict creditworthiness
predictions = model.predict(sample_data)
sample_data["Predicted Creditworthiness"] = predictions

# Show results
print(sample_data[["age", "balance", "Predicted Creditworthiness"]])

